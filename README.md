# RAG-Samples-Project

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/qlfv/RAG-Samples-Project/blob/main/demo_rag.ipynb)

Ce projet d√©montre la G√©n√©ration Augment√©e par Recherche (RAG)‚ÄØ: comment combiner recherche documentaire et g√©n√©ration de texte pour des r√©ponses plus pr√©cises.

---

## üöÄ Quickstart

```bash
# Clone le repo
git clone https://github.com/qlfv/RAG-Samples-Project.git
cd RAG-Samples-Project

# Installe les d√©pendances (environnement Python >=3.8)
pip install -r requirements.txt
```

Ou ouvre directement le notebook sur [Google Colab](https://colab.research.google.com/github/qlfv/RAG-Samples-Project/blob/main/demo_rag.ipynb).

---

## üß† Sch√©ma du pipeline RAG

```
[Question utilisateur]
          |
   [Embeddings]
          |
   [Recherche dans index vectoriel]
          |
   [Passage retrouv√©]
          |
   [G√©n√©ration de r√©ponse (LLM)]
          |
   [R√©ponse augment√©e]
```

---

## üìö Pour aller plus loin

- [LangChain](https://python.langchain.com/)
- [LlamaIndex](https://www.llamaindex.ai/)
- [Haystack](https://haystack.deepset.ai/)
- [Paper original RAG (Facebook)](https://arxiv.org/abs/2005.11401)

---

## üìÇ Structure recommand√©e

- `demo_rag.ipynb` : Notebook de d√©mo minimal
- `src/` : Scripts Python modulaires (retrieval.py, generation.py‚Ä¶)
- `data/` : Mini-datasets d‚Äôexemple
- `README.md` : Documentation, sch√©mas, liens

---

## üìù Licence

Ce projet est open source (MIT).

---

## ‚ö†Ô∏è Limites des mod√®les utilis√©s et bonnes pratiques

- Le mod√®le par d√©faut utilis√© pour la g√©n√©ration est **GPT-2** (HuggingFace). Il n'est pas sp√©cialis√© pour le fran√ßais ni pour le question/r√©ponse technique‚ÄØ: il fonctionne nettement mieux en anglais.
- **Hallucinations**‚ÄØ: GPT-2 peut inventer des r√©ponses ou des noms de frameworks qui n'existent pas (ex‚ÄØ: "LlamaTk").
- **Compr√©hension limit√©e**‚ÄØ: il peut g√©n√©rer des phrases grammaticalement correctes mais sans sens technique pr√©cis.
- **Prompting**‚ÄØ: la qualit√© du prompt (instructions, formulation) influence fortement la pertinence de la r√©ponse.
- **Pas de connaissances r√©centes**‚ÄØ: GPT-2 ne conna√Æt pas les frameworks ou concepts apparus apr√®s 2019.

### Bonnes pratiques pour de meilleurs r√©sultats

- Privil√©gier l'anglais pour la g√©n√©ration avec GPT-2.
- Pour le fran√ßais, utiliser un mod√®le francophone (ex‚ÄØ: `cmarkea/gpt2-small-french`) ou un pipeline "question-answering" (`illuin/camembert-base-fquad`).
- Structurer les prompts‚ÄØ: donner des instructions claires, pr√©ciser le contexte et la question.
- Tester plusieurs mod√®les selon la t√¢che (g√©n√©ration libre vs Q&A).
- Toujours valider la r√©ponse g√©n√©r√©e avant de la pr√©senter √† un utilisateur final.

---

## ‚ùì FAQ sur la g√©n√©ration IA (RAG)

**Q : Pourquoi la r√©ponse g√©n√©r√©e n‚Äôest-elle pas toujours pertinente ?**
> Les mod√®les comme GPT-2 ne comprennent pas r√©ellement le sens‚ÄØ: ils pr√©disent la suite la plus probable du texte. Ils peuvent donc g√©n√©rer des phrases correctes mais factuellement fausses ou hors sujet.

**Q : Comment √©viter que le mod√®le ‚Äúinvente‚Äù des informations ?**
> Utilisez des mod√®les sp√©cialis√©s pour le question/r√©ponse (pipeline "question-answering") et structurez bien le prompt. Pour des t√¢ches critiques, validez toujours la r√©ponse g√©n√©r√©e.

**Q : Peut-on utiliser d‚Äôautres mod√®les que GPT-2 ?**
> Oui‚ÄØ! Essayez des mod√®les plus r√©cents ou sp√©cialis√©s (GPT-J, Falcon, Mistral, mod√®les francophones, etc.) disponibles sur HuggingFace.

**Q : Comment am√©liorer la g√©n√©ration en fran√ßais ?**
> Utilisez un mod√®le francophone (ex‚ÄØ: `cmarkea/gpt2-small-french`) ou un mod√®le Q&A entra√Æn√© sur des donn√©es fran√ßaises (`illuin/camembert-base-fquad`).

**Q : Pourquoi le mod√®le ne conna√Æt-il pas les frameworks r√©cents ?**
> Les mod√®les ont √©t√© entra√Æn√©s sur des donn√©es arr√™t√©es √† une certaine date (ex‚ÄØ: 2019 pour GPT-2). Ils ne connaissent pas les nouveaut√©s apparues apr√®s.

**Q : Peut-on utiliser RAG avec des documents PDF ou des sites web ?**
> Oui, il suffit d‚Äôextraire le texte des documents et de l‚Äôindexer avec la m√™me logique (voir les frameworks comme LangChain ou LlamaIndex pour des pipelines avanc√©s).

---

**N‚Äôh√©sitez pas √† proposer des am√©liorations ou √† ouvrir des issues‚ÄØ!**
- **Manipulation et extraction d'informations** : La base de donn√©es vectorielle FAISS est utilis√©e pour la recherche de similarit√©s et la g√©n√©ration de r√©ponses bas√©es sur les informations pertinentes.

## Structure des Fichiers

- `load_and_segment_documents.py` : Script pour le chargement, la segmentation et la vectorisation des documents PDF.
- `query_vector_database.py` : Script pour interroger la base de donn√©es vectorielle et r√©cup√©rer les informations pertinentes.
- `vector_db.pkl` : Fichier contenant la base de donn√©es vectorielle g√©n√©r√©e √† partir des embeddings des documents.
- `README.md` : Ce fichier, qui explique la structure et les objectifs du projet.
- `requirements.txt` : Liste des d√©pendances Python n√©cessaires pour ex√©cuter les scripts.

## Pr√©requis

Avant de lancer les scripts, assurez-vous que les √©l√©ments suivants sont install√©s :

- **Python** 3.8 ou sup√©rieur
- Les biblioth√®ques Python list√©es dans `requirements.txt`.

Installez les d√©pendances via pip :

```bash
pip install -r requirements.txt
```

## Exemple de Code :

### Chargement et Segmentation de Documents PDF

Le code pour charger et segmenter des documents PDF se trouve dans le fichier [`load_and_segment_documents.py`](./load_and_segment_documents.py).

### Recherche dans la Base de Donn√©es Vectorielle

Le code pour interroger la base de donn√©es vectorielle se trouve dans le fichier [`query_vector_database.py`](./query_vector_database.py).

## Contributions

Les contributions sont les bienvenues. Veuillez soumettre des demandes de tirage (PR) avec des descriptions d√©taill√©es des modifications.

## Licence

Ce projet est sous licence MIT. Veuillez vous r√©f√©rer au fichier LICENSE pour plus d'informations.

